# =============================================================================
# Scamnemesis - Docker Compose for Production
# =============================================================================
# Kompletna produkcia s Traefik (automaticke SSL) a vsetkymi sluzbami
#
# Pouzitie:
#   1. Skopiruj .env.example do .env a nastav hodnoty
#   2. docker compose -f docker-compose.prod.yml up -d
#   3. Pockaj 5-10 minut na inicializaciu
# =============================================================================

# Default logging configuration to prevent disk fill
x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "50m"
    max-file: "5"
    compress: "true"

services:
  # ===========================================================================
  # TRAEFIK - Reverse Proxy + Automaticke SSL certifikaty
  # ===========================================================================
  traefik:
    image: traefik:v2.11
    container_name: scamnemesis-traefik
    restart: always
    logging: *default-logging
    command:
      # =======================================================================
      # Docker Provider Configuration
      # =======================================================================
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.docker.network=scamnemesis_network_prod"

      # =======================================================================
      # Entrypoints (HTTP and HTTPS)
      # =======================================================================
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"

      # =======================================================================
      # Let's Encrypt Certificate Configuration (DNS-01 Challenge)
      # DNS-01 works with Cloudflare proxy mode (orange cloud) enabled!
      # =======================================================================
      - "--certificatesresolvers.letsencrypt.acme.dnschallenge=true"
      - "--certificatesresolvers.letsencrypt.acme.dnschallenge.provider=cloudflare"
      - "--certificatesresolvers.letsencrypt.acme.dnschallenge.delaybeforecheck=10"
      - "--certificatesresolvers.letsencrypt.acme.dnschallenge.resolvers=1.1.1.1:53,8.8.8.8:53"
      - "--certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL}"
      - "--certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json"
      # IMPORTANT: Uncomment line below for testing to avoid Let's Encrypt rate limits
      # - "--certificatesresolvers.letsencrypt.acme.caserver=https://acme-staging-v02.api.letsencrypt.org/directory"

      # =======================================================================
      # Logging and API
      # =======================================================================
      - "--log.level=INFO"
      - "--accesslog=true"
      - "--api.dashboard=false"
      - "--ping=true"
    ports:
      - "80:80"
      - "443:443"
    environment:
      # Cloudflare API for DNS-01 challenge (required for SSL certificates)
      # IMPORTANT: Must be CF_DNS_API_TOKEN (not CF_API_TOKEN) - this is what lego/Traefik expects
      - CF_DNS_API_TOKEN=${CLOUDFLARE_API_TOKEN}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik_certs:/letsencrypt
    networks:
      - scamnemesis
    healthcheck:
      test: ["CMD", "traefik", "healthcheck", "--ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  # ===========================================================================
  # DATABASE MIGRATIONS (Prisma - runs before app starts)
  # ===========================================================================
  # NOTE: This service ensures database schema is ready before app starts.
  # The app entrypoint also runs migrations as a safety net.
  migrations:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: scamnemesis-migrations
    user: root  # Required for apt-get install fallback
    logging: *default-logging
    environment:
      - NODE_ENV=production
      - HOME=/tmp
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-scamnemesis}
    depends_on:
      postgres:
        condition: service_healthy
      password-sync:
        condition: service_completed_successfully
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "=== Running Prisma migrations ==="
        # Construct DATABASE_URL with encoded password
        ENCODED_PASSWORD=$$(node -e "console.log(encodeURIComponent(process.argv[1]))" "$$POSTGRES_PASSWORD")
        export DATABASE_URL="postgresql://$$POSTGRES_USER:$$ENCODED_PASSWORD@postgres:5432/$$POSTGRES_DB"

        # Use direct path to Prisma CLI (npx not available in production image)
        PRISMA_BIN="/app/node_modules/.bin/prisma"

        # Try migrate deploy first (production-safe)
        if $$PRISMA_BIN migrate deploy 2>&1; then
          echo "=== Prisma migrations applied successfully! ==="
          exit 0
        fi

        # Fallback to db push for fresh installs
        echo "migrate deploy failed, trying db push..."
        if $$PRISMA_BIN db push --skip-generate 2>&1; then
          echo "=== Database schema synchronized! ==="
          exit 0
        fi

        echo "=== Prisma failed, falling back to direct SQL execution ==="
        # Install psql client temporarily and run raw SQL
        apt-get update -qq && apt-get install -y -qq postgresql-client > /dev/null 2>&1

        # Run the baseline migration SQL directly
        if [ -f "/app/prisma/migrations/0_baseline/migration.sql" ]; then
          echo "Running baseline migration SQL..."
          PGPASSWORD="$$POSTGRES_PASSWORD" psql -h postgres -U "$$POSTGRES_USER" -d "$$POSTGRES_DB" -f /app/prisma/migrations/0_baseline/migration.sql 2>&1
          if [ $$? -eq 0 ]; then
            echo "=== SQL migration applied successfully! ==="
            exit 0
          fi
        fi

        echo "ERROR: All migration methods failed!"
        exit 1
    networks:
      - scamnemesis
    restart: "no"

  # ===========================================================================
  # NEXT.JS APPLICATION (Frontend + Backend API)
  # ===========================================================================
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
      args:
        - SENTRY_AUTH_TOKEN=${SENTRY_AUTH_TOKEN:-}
        - SENTRY_ORG=${SENTRY_ORG:-m0ne-sro}
        - SENTRY_PROJECT=${SENTRY_PROJECT:-scamnemesis}
    container_name: scamnemesis-app
    restart: always
    logging: *default-logging
    environment:
      - NODE_ENV=production
      - PORT=3000
      # Database credentials passed separately for URL encoding in entrypoint
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-scamnemesis}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-scamnemesis_redis_2024}@redis:6379
      - S3_ENDPOINT=http://minio:9000
      - S3_ACCESS_KEY=${S3_ACCESS_KEY:-minioadmin}
      - S3_SECRET_KEY=${S3_SECRET_KEY:-minioadmin}
      - S3_BUCKET=scamnemesis
      - S3_REGION=us-east-1
      - JWT_SECRET=${JWT_SECRET}
      - JWT_REFRESH_SECRET=${JWT_REFRESH_SECRET}
      - JWT_EXPIRES_IN=15m
      - JWT_REFRESH_EXPIRES_IN=7d
      - TYPESENSE_HOST=typesense
      - TYPESENSE_PORT=8108
      - TYPESENSE_PROTOCOL=http
      - TYPESENSE_API_KEY=${TYPESENSE_API_KEY:-changeme}
      - ML_SERVICE_URL=http://ml-service:8000
      - CLAMAV_HOST=clamav
      - CLAMAV_PORT=3310
      - NEXT_PUBLIC_API_URL=https://${DOMAIN:-localhost}
      - NEXT_PUBLIC_DOMAIN=${DOMAIN:-localhost}
      - NEXT_PUBLIC_SITE_URL=https://${DOMAIN:-localhost}
      # Admin setup (generate secure values!)
      - ADMIN_SETUP_TOKEN=${ADMIN_SETUP_TOKEN}
      - ADMIN_EMAIL=${ADMIN_EMAIL:-admin@scamnemesis.com}
      # Auth.js (NextAuth v5) - CRITICAL for authentication
      - AUTH_SECRET=${AUTH_SECRET}
      - AUTH_TRUST_HOST=true
      - NEXTAUTH_URL=https://${DOMAIN:-localhost}
      # Sentry error tracking (runtime)
      - SENTRY_ORG=${SENTRY_ORG:-m0ne-sro}
      - SENTRY_PROJECT=${SENTRY_PROJECT:-scamnemesis}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    labels:
      - "traefik.enable=true"
      # CRITICAL: Tell Traefik which network to use for backend communication
      - "traefik.docker.network=scamnemesis_network_prod"
      # Define the backend service (CRITICAL - must be defined for routers to work)
      - "traefik.http.services.app.loadbalancer.server.port=3000"
      # =======================================================================
      # Main HTTPS router (primary domain)
      # =======================================================================
      - "traefik.http.routers.app.rule=Host(`${DOMAIN:-localhost}`)"
      - "traefik.http.routers.app.entrypoints=websecure"
      - "traefik.http.routers.app.tls=true"
      - "traefik.http.routers.app.tls.certresolver=letsencrypt"
      - "traefik.http.routers.app.service=app"

      # =======================================================================
      # HTTP to HTTPS redirect router (primary domain)
      # =======================================================================
      - "traefik.http.routers.app-http.rule=Host(`${DOMAIN:-localhost}`)"
      - "traefik.http.routers.app-http.entrypoints=web"
      - "traefik.http.routers.app-http.middlewares=https-redirect"
      - "traefik.http.routers.app-http.service=app"

      # =======================================================================
      # WWW to non-WWW redirect (HTTPS) - FIXED: Explicit TLS enable
      # =======================================================================
      - "traefik.http.routers.app-www.rule=Host(`www.${DOMAIN:-localhost}`)"
      - "traefik.http.routers.app-www.entrypoints=websecure"
      - "traefik.http.routers.app-www.tls=true"
      - "traefik.http.routers.app-www.tls.certresolver=letsencrypt"
      - "traefik.http.routers.app-www.middlewares=www-redirect"
      - "traefik.http.routers.app-www.service=app"

      # =======================================================================
      # WWW HTTP to non-WWW HTTPS redirect
      # =======================================================================
      - "traefik.http.routers.app-www-http.rule=Host(`www.${DOMAIN:-localhost}`)"
      - "traefik.http.routers.app-www-http.entrypoints=web"
      - "traefik.http.routers.app-www-http.middlewares=www-redirect-http"
      - "traefik.http.routers.app-www-http.service=app"

      # =======================================================================
      # Middleware definitions
      # =======================================================================
      - "traefik.http.middlewares.https-redirect.redirectscheme.scheme=https"
      - "traefik.http.middlewares.https-redirect.redirectscheme.permanent=true"
      - "traefik.http.middlewares.www-redirect.redirectregex.regex=^https://www\\.(.*)"
      - "traefik.http.middlewares.www-redirect.redirectregex.replacement=https://$${1}"
      - "traefik.http.middlewares.www-redirect.redirectregex.permanent=true"
      - "traefik.http.middlewares.www-redirect-http.redirectregex.regex=^http://www\\.(.*)"
      - "traefik.http.middlewares.www-redirect-http.redirectregex.replacement=https://$${1}"
      - "traefik.http.middlewares.www-redirect-http.redirectregex.permanent=true"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/v1/health"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 90s
    networks:
      - scamnemesis
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

  # ===========================================================================
  # DATABASE (PostgreSQL + pgvector)
  # ===========================================================================
  postgres:
    image: pgvector/pgvector:pg16
    container_name: scamnemesis-postgres
    restart: unless-stopped
    logging: *default-logging
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-scamnemesis}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_socket:/var/run/postgresql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scamnemesis
    stop_grace_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

  # ===========================================================================
  # PASSWORD SYNC (ensures DB password matches .env on every deploy)
  # ===========================================================================
  # This service runs before migrations and updates the PostgreSQL password
  # to match the current .env file. This is necessary because the postgres
  # docker image only uses POSTGRES_PASSWORD during initial database creation.
  password-sync:
    image: pgvector/pgvector:pg16
    container_name: scamnemesis-password-sync
    user: "999:999"  # postgres user UID:GID in Debian-based pgvector image (matches postgres service)
    logging: *default-logging
    environment:
      - PGUSER=${POSTGRES_USER:-postgres}
      - PGDATABASE=${POSTGRES_DB:-scamnemesis}
      - NEW_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_socket:/var/run/postgresql
    depends_on:
      postgres:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "[password-sync] Syncing PostgreSQL password with .env..."
        # Connect via unix socket (local trust authentication)
        # This works even if the current password is different from .env
        psql -h /var/run/postgresql -U "$${PGUSER}" -d "$${PGDATABASE}" -c "ALTER USER $${PGUSER} PASSWORD '$${NEW_PASSWORD}';" && \
        echo "[password-sync] Password synchronized successfully!" || \
        echo "[password-sync] Warning: Password sync failed (check logs)"
    networks:
      - scamnemesis
    restart: "no"

  # ===========================================================================
  # CACHE & MESSAGE QUEUE (Redis)
  # ===========================================================================
  redis:
    image: redis:7.4-alpine
    container_name: scamnemesis-redis
    restart: unless-stopped
    logging: *default-logging
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru --requirepass ${REDIS_PASSWORD:-scamnemesis_redis_2024}
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_PASSWORD:-scamnemesis_redis_2024}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scamnemesis
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M

  # ===========================================================================
  # SEARCH ENGINE (Typesense)
  # ===========================================================================
  typesense:
    image: typesense/typesense:0.25.2
    container_name: scamnemesis-typesense
    restart: unless-stopped
    logging: *default-logging
    environment:
      - TYPESENSE_DATA_DIR=/data
      - TYPESENSE_API_KEY=${TYPESENSE_API_KEY:-changeme}
      - TYPESENSE_ENABLE_CORS=false
    volumes:
      - typesense_data:/data
    healthcheck:
      # Note: Typesense image doesn't include curl, use wget instead
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8108/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - scamnemesis
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  # ===========================================================================
  # ML SERVICE (Python FastAPI)
  # ===========================================================================
  ml-service:
    build:
      context: ./services/ml
      dockerfile: Dockerfile
    container_name: scamnemesis-ml
    restart: unless-stopped
    logging: *default-logging
    environment:
      # Pass credentials separately, construct URL in entrypoint with encoding
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-scamnemesis}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-scamnemesis_redis_2024}@redis:6379
      - MODEL_CACHE_DIR=/models
      - LOG_LEVEL=INFO
    volumes:
      - ml_models:/models
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - scamnemesis
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  # ===========================================================================
  # VIRUS SCANNING
  # ===========================================================================
  clamav:
    image: clamav/clamav:1.4.1
    container_name: scamnemesis-clamav
    restart: unless-stopped
    logging: *default-logging
    volumes:
      - clamav_data:/var/lib/clamav
    networks:
      - scamnemesis
    healthcheck:
      # Use echo + clamdscan to verify clamd is running and responsive
      test: ["CMD-SHELL", "echo PING | clamdscan --stream - 2>&1 | grep -q 'Infected files: 0' || exit 1"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 300s
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  # ===========================================================================
  # MINIO - S3 kompatibilne ulozisko
  # ===========================================================================
  minio:
    image: minio/minio:RELEASE.2024-11-07T00-52-20Z
    container_name: scamnemesis-minio
    restart: always
    logging: *default-logging
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${S3_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_KEY:-minioadmin}
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - scamnemesis
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  minio-init:
    image: minio/mc:RELEASE.2024-11-21T17-21-54Z
    container_name: scamnemesis-minio-init
    logging: *default-logging
    restart: "no"
    depends_on:
      minio:
        condition: service_healthy
    environment:
      - S3_ACCESS_KEY=${S3_ACCESS_KEY:-minioadmin}
      - S3_SECRET_KEY=${S3_SECRET_KEY:-minioadmin}
    entrypoint: >
      /bin/sh -c "
      sleep 10;
      mc alias set myminio http://minio:9000 $${S3_ACCESS_KEY} $${S3_SECRET_KEY};
      mc mb myminio/scamnemesis --ignore-existing;
      mc anonymous set download myminio/scamnemesis/public;
      exit 0;
      "
    networks:
      - scamnemesis

  # ===========================================================================
  # MONITORING (volitelne - mozno vypnut)
  # ===========================================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: scamnemesis-prometheus
    restart: unless-stopped
    logging: *default-logging
    depends_on:
      app:
        condition: service_healthy
    volumes:
      - ./config/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - scamnemesis
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  grafana:
    image: grafana/grafana:10.2.0
    container_name: scamnemesis-grafana
    restart: unless-stopped
    logging: *default-logging
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    volumes:
      - ./config/grafana/provisioning:/etc/grafana/provisioning
      - grafana_data:/var/lib/grafana
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - scamnemesis
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

# ===========================================================================
# VOLUMES
# ===========================================================================
volumes:
  traefik_certs:
    name: scamnemesis_traefik_certs_prod
  postgres_data:
    name: scamnemesis_postgres_data_prod
  postgres_socket:
    name: scamnemesis_postgres_socket_prod
  redis_data:
    name: scamnemesis_redis_data_prod
  ml_models:
    name: scamnemesis_ml_models_prod
  typesense_data:
    name: scamnemesis_typesense_data_prod
  clamav_data:
    name: scamnemesis_clamav_data_prod
  minio_data:
    name: scamnemesis_minio_data_prod
  prometheus_data:
    name: scamnemesis_prometheus_data_prod
  grafana_data:
    name: scamnemesis_grafana_data_prod

# ===========================================================================
# NETWORKS
# ===========================================================================
networks:
  scamnemesis:
    name: scamnemesis_network_prod
    driver: bridge
